---
title: "Convolutional Neural Networks"
author: "Jennifer Scodes and Yimo Zhang"

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Convolutional neural networks (CNN) are feed-forward neural networks that specialize in processing data with a grid-like structure such as images. They can consist of convolutional layers, pooling layers, and fully connected layers but must have at least one convolutional layer. The convolutional and pooling layers compute feature extraction while the fully connected layer maps the features to the final output (i.e., classification). Within an image, the 2-dimensional space is defined by pixels to represent the visual data. The pixels can denote specific RGB color and brightness, so feature extraction begins within each pixel, and as each layer feeds into the next in a hierarchy, the features can become more complex (Yamashita et al. 2015; IBM). This eventually enables CNN to detect simple to complex patterns within the image. 

<center>
<img src="images/overallCNN.png" width=80% height=80%>
  <figcaption>Figure 1. Overview of CNN structure (Yamashita et al. 2015)</figcaption>
</center>


### The Impact of CNNs

CNNs have surged in popularity given their demonstrated potential for object recognition in images (Yamashita et al., 2018). They have provided astonishing results in object recognition in competitions such as the ImageNet Large Scale Visual Recognition Challenge where the competition reached a turning point from 2012 and onward with the introduction of CNNs that started dominating all three tasks of image classification, single-object localization, and object detection (Russakovsky et al., 2015; Krizhevsky and Sutskever, 2012). The performances seen in CNNs have reached levels previously thought to only be within the human realm (Teuwen and Moriakova, 2020), and have been implemented all around us in a variety of fields such as in marketing for identifying people in photos, in healthcare for medical imaging, and even in automotive safety technology such as lane detection (IBM).

From a public health perspective, CNN has been of interest in medical research, especially radiology, for lesion detection, classification, segmentation, and image reconstruction (Yamashita et al, 2018). Its application has already been widespread and successful. For example, in a recent study aimed at evaluating the prediction performance of CNNs in diagnosing thyroid cancer from ultrasound images, Kim et al. found that CNNs had diagnostic performance comparable to experienced radiologists (AUC= 0.917 vs 0.891, respectively) (2021). In another study assessing CNNs ability to identify varying types of skin cancers in images, Esteva et al. found that CNNs achieved AUCs over 91% in identifying carcinoma and melanoma skin cancer (2017). With results like these, the effective implementation of CNN in radiological image screening can have a large and important impact in clinical practice for discovering and diagnosing disease. 

### What exactly are CNNs?

Convolutional neural networks are a specific type of neural networks that assume the inputs are structured as images. What this means is that CNNs have the same architecture as regular neural networks as in they are made up of neurons, defined as a nonlinearity applied to an affine function, with learnable weights and are trained in a similar fashion as neural networks. They consist of input layers, hidden layers, and an output layer.  An example network is the following:

<center>
<img src="images/exampleNN.png" width=40% height=40%>
  <figcaption>Figure 2. Example neural network with an input layer, 2 hidden layers (the first with width=5 neurons and second with width=3 neurons), and an output layer for a total of 27 trainable parameters. (Teuwen and Moriakova, 2020)</figcaption>
</center>

<br>
In the feedforward process, the input layer contains features, $\textbf{x}$ where $\textbf{x}$ is a $p$ x 1 matrix for $p$ input parameters that are passed through a function, $\textbf{z}^{(1)}=\sigma(\textbf{b}^{(1)} +\textbf{W}^{(1)}\textbf{x})$, with weight ($\textbf{W}$ a $m$ x $p$ matrix for m nodes in hidden layer 1), bias ($\textbf{b}$ as a m x 1 matrix), and activation function ($\sigma$) for each of the nodes in the first hidden layer (layer is indicated by $^{(1)}$ superscript). Common choices for activation functions are the sigmoid $\sigma(x)=\frac{1}{1+e^{-x}}$ and relu functions $\sigma(x)=max(0,x)$. Therefore, we can see that each node in the first hidden layer is a weighted combination of input values with an activation function applied. This process continues in a feedforward approach where the nodes in the second hidden layer will be a weighted combination of the first hidden layer ($\textbf{z}^{(2)}=\sigma(\textbf{b}^{(2)} +\textbf{W}^{(2)}\textbf{z}^{(1)}$), until we reach the output layer. The output layer contains a single node and typically a linear activation function $\sigma(x)=x$ to give an estimated value of the outcome, y, which could be a class for classification or a real value for regression.

The networks weights and bias values can then be trained to minimize the loss function relative to the outcome's distribution. For example, for continuous outcomes the loss function is squared error: $L(y, \hat f(x))=(y-\hat f(x))^2$ and for binary outcomes the loss function is binary cross entropy: $L(y, \hat f(x))=ylog(\hat f(x))+ (1-y)log(1-\hat f(x))$. Gradient-based optimization, such as stochastic gradient descent, can be used to minimize the loss function by computing the network's gradients through backpropagation. For more details see Teuwen and Moriakova (2020).

CNNs have the same structure as these feedforward networks (see Figure 3); however, what makes them unique is the assumption that the inputs $\textbf{x}$ are in a grid-like structure, such as in images. Because of this assumption, for imaging, the input data is stored in pixel values in a 2D grid with height, width, and depth. Then the data pass through convolution, pooling and fully connected layers as described below. 


<center>
<img src="images/ForwardpropCNN.png" width=90% height=90%>
  <figcaption>Figure 3. Overview of the typical architecture of a convolutional neural network (Yamashita et al. 2018)</figcaption>
</center>

#### Convolution Layer

The convolutional layer of CNN is the bread and butter of the network because it performs the feature extraction, and does so through a linear operation called convolution. In the feedforward process, a kernel filter slides across the 2-D or 3-D inputs to compute a feature map of the filter. This feature map is the sum of the element-wise product of the kernel and the input tensor (an array of numbers from sliding across the full input data). The kernel size can typically be 3x3, or larger such as 7x7, and usually moves along the image in steps of one unit (stride). An example of kernel size 3x3 with a stride size of 1 is presented in Figure 4. 

<center>
<img src="images/featuremap.png" width=50% height=50%>
  <figcaption>Figure 4. An example of convolution with a kernel size of 3x3 and a stride of 1 (Yamashita et al. 2018)</figcaption>
</center>

<br>

The kernels can then be applied consecutively to increase the depth of the feature map. The size, number of kernels, and stride length values need to be set prior to the training process, but the kernels weights are optimized through backpropogation. A key advantage of CNNs is how the kernels are invariant across all inputs across the image. This increases model efficiency since it reduces the number of parameters needing to be learned. The outputs of the convolutions then pass through a non-linear function such as the ReLU function. (Yamashita et al., 2018; Teuwen and Moriakova, 2020)

#### Pooling Layer

The pooling layer is a dimension reduction layer that reduces the dimensionality of the feature maps through summary statistics. This is done to decrease the number of learnable parameters and to add invariance to small distortions in the image. Two common approaches are max pooling and average pooling. For max pooling, the maximum values are taken over patches of the input feature maps. Average pooling is similar but takes the average instead of the maximum. Common partitions are 2x2 blocks with stride 2. There are no learnable parameters in pooling layers. (Yamashita et al., 2018; Teuwen and Moriakova, 2020)

#### Fully Connected Layer

After pooling, the feature maps are transformed into vectors (1-D arrays), and then input into the fully connected layers. These layers consist of every input connected to every output through a non-linear function with a weight and bias term. The final fully connected layer contains the activation function specific to the distribution of the output such as the sigmoid function for binary classification or identity function for continuous values. (Yamashita et al. 2018; Teuwen and Moriakova, 2020)

### Training CNNs

Finally, such as in the neural networks, CNNs have to be trained. For CNNs, this involves finding the convolution layer kernels and fully connected layer weights and biases that minimize the loss function. Similar to neural networks, the input data is first fed forward through the network, and the loss function, such as the difference between output predictions and true values, is computed. Then, the learnable parameters are updated through backpropogation and gradient descent. This process repeats until the loss function is minimized. Available data should be split into training, test, and validation sets in order to train the hyperparameters of the model. 


### Example Application of CNN
<br>
<br>


### References
- Esteva, A., Kuprel, B., Novoa, R. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017). https://doi.org/10.1038/nature21056

- Krizhevsky, A., Sutskever, I., Hinton, GE. ImageNet classification with deep convolutional neural networks. Adv Neural Inf Process Syst 25. (2012) Available online at: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf. Accessed 26 Apr 2023

- Russakovsky, O., Deng, J., Su, H. et al. ImageNet Large Scale Visual Recognition Challenge. Int J Comput Vis 115, 211–252 (2015). https://doi.org/10.1007/s11263-015-0816-y


- Teuwen, J., and Moriakova, N. Handbook of Medical Image Computing and Computer Assisted Intervention. Chapter 20: Convolutional neural networks. (2020) https://doi.org/10.1016/B978-0-12-816176-0.00025-9 

- Yamashita, R., Nishio, M., Do, R.K.G. et al. Convolutional neural networks: an overview and application in radiology. Insights Imaging 9, 611–629 (2018). https://doi.org/10.1007/s13244-018-0639-9

- Convolutional Neural Networks. IBM. Retrieved April 26, 2023, from https://www.ibm.com/topics/convolutional-neural-networks


<br>
